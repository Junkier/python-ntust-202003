{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e87219d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 591 租屋網\n",
    "\n",
    "# 必須要有 cookies & X-CSRF-TOKEN\n",
    "\n",
    "### 一次性   --> 手動複製 cookies & X-CSRF-Token 即可\n",
    "\n",
    "### 定期爬蟲 --> 須先向首頁發 requests 設定 cookies & 取得 csrf-token \n",
    "\n",
    "# 1. 建立 session \n",
    "# 2. sess 向首頁發 requests , 設定 cookies --> \"https://rent.591.com.tw/\"\n",
    "# 3. 取得 csrf-token \n",
    "# 4. GET API 抓資料\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"https://rent.591.com.tw/home/search/rsList?is_format_data=1&is_new_list=1&type=1&section=3&searchtype=1&multiArea=10_20&showMore=1\"\n",
    "headers = {\n",
    "    \"Accept\": \"application/json, text/javascript, */*; q=0.01\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Accept-Language\": \"zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Cookie\": \"webp=1; PHPSESSID=g3u3tnc81fjrk7ighgv2mkr3m4; urlJumpIp=1; urlJumpIpByTxt=%E5%8F%B0%E5%8C%97%E5%B8%82; newUI=1; T591_TOKEN=g3u3tnc81fjrk7ighgv2mkr3m4; _ga=GA1.3.1649913125.1636598035; _gid=GA1.3.822631898.1636598035; _ga=GA1.4.1649913125.1636598035; _gid=GA1.4.822631898.1636598035; _fbp=fb.2.1636598035774.332302313; user_index_role=1; __auc=2f8d3e4717d0ce987014f765288; __utma=82835026.1649913125.1636598035.1636599171.1636599171.1; __utmc=82835026; __utmz=82835026.1636599171.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none); new_rent_list_kind_test=0; tw591__privacy_agree=1; user_browse_recent=a%3A5%3A%7Bi%3A0%3Ba%3A2%3A%7Bs%3A4%3A%22type%22%3Bi%3A1%3Bs%3A7%3A%22post_id%22%3Bi%3A11593829%3B%7Di%3A1%3Ba%3A2%3A%7Bs%3A4%3A%22type%22%3Bi%3A1%3Bs%3A7%3A%22post_id%22%3Bi%3A11569362%3B%7Di%3A2%3Ba%3A2%3A%7Bs%3A4%3A%22type%22%3Bi%3A1%3Bs%3A7%3A%22post_id%22%3Bi%3A11569222%3B%7Di%3A3%3Ba%3A2%3A%7Bs%3A4%3A%22type%22%3Bi%3A1%3Bs%3A7%3A%22post_id%22%3Bi%3A11569231%3B%7Di%3A4%3Ba%3A2%3A%7Bs%3A4%3A%22type%22%3Bi%3A1%3Bs%3A7%3A%22post_id%22%3Bi%3A11668431%3B%7D%7D; XSRF-TOKEN=eyJpdiI6ImtqQ1VTcjBwNGpEUnZ5UlVYd3VxV3c9PSIsInZhbHVlIjoiaDlndnZVbHV1RmNyRkZ1MDFXYmV2VDlpUk1JbzNSa2syajRobTJDYXJqbjlkS1FSNjJDZjhRWTk4TjRoc2JwdUFKYU9ON2lMcSswaUxUT0h1V3NyaFE9PSIsIm1hYyI6IjM2OGQ0NjJmNDc2N2NiNGMzMDVjN2RlMGM3NzRkYjY4MmEyYTQ5YTFmMjRmMDE1OWI3OWI0NzVhYjMzMjRmY2MifQ%3D%3D; 591_new_session=eyJpdiI6IkRlRDgxU1BQcW1PdmQ3YWV4ODB3SkE9PSIsInZhbHVlIjoiZElmNUlPdlErZXhBbEdxZWhiOHNReThDRDI4dHRTRk5oUkx2aTdHbkJRVGVWdEkzY1VDWWloSzU4bmJNWHgxSVNcL0w2ZHpGUXJab0lJU1pZVGVnUlNRPT0iLCJtYWMiOiI0NmMxYTU4NzRlMDQ2NTdmN2VjYTZjMjllOWNiZDM4YTg4YWFhZjJjNDYwYzE1YWRjM2U5N2NjNDE4MGJkMDc2In0%3D; _gat_UA-97423186-1=1\",\n",
    "    \"Host\": \"rent.591.com.tw\",\n",
    "    \"Referer\": \"https://rent.591.com.tw/?section=3&searchtype=1\",\n",
    "    \"sec-ch-ua\": 'Not A;Brand\";v=\"99\", \"Chromium\";v=\"90\", \"Google Chrome\";v=\"90',\n",
    "    \"sec-ch-ua-mobile\": \"?0\",\n",
    "    \"Sec-Fetch-Dest\": \"empty\",\n",
    "    \"Sec-Fetch-Mode\": \"cors\",\n",
    "    \"Sec-Fetch-Site\": \"same-origin\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\",\n",
    "    \"X-CSRF-TOKEN\": \"XHjHwC4QhRaouTQzmpbbgNsLL032x3ooqaoMcKkp\",\n",
    "    \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "    # \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\"\n",
    "}\n",
    "res = requests.get(url,headers = headers)\n",
    "# print(res.text)\n",
    "# print(res)\n",
    "# print(res.json())\n",
    "raw_data = res.json()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db52b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3def997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679ec0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4691557f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 取得本文 source code 完成！\n",
      "* 抓取首頁文章連結 完成！\n",
      "https://www.ptt.cc/bbs/Stock/index5000.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/index4999.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/index4998.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/index4997.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/index4996.html is ok.\n",
      "* 抓取分頁文章連結 完成！\n",
      "https://www.ptt.cc/bbs/Stock/M.1637022288.A.0E7.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1637022519.A.573.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1637023332.A.35E.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1637024042.A.B6C.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1637024832.A.654.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1637025475.A.637.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1637029138.A.F23.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1637030088.A.E46.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1637030926.A.0BD.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/M.1637031326.A.D88.html is ok.\n",
      "* 抓取文章資料 完成！\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "##### Pandas \n",
    "### 以 Ptt 股票版爬蟲 為例\n",
    "\n",
    "## 引用套件\n",
    "import requests\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup as bs \n",
    "\n",
    "## 定義 function\n",
    "\n",
    "# 移除標籤\n",
    "# - div.article-metaline\n",
    "# - div.article-metaline-right\n",
    "# - span.f2\n",
    "def remove_dirty_tag(soup):\n",
    "    \n",
    "    # 若存在 , 則移除標籤\n",
    "    if len(soup.select(\"div.article-metaline\")) >0 :\n",
    "        \n",
    "        # 標籤可能多項 , 使用 for-loop 移除\n",
    "        for tag in soup.select(\"div.article-metaline\"):\n",
    "            tag.extract()\n",
    "            \n",
    "    if len(soup.select(\"div.article-metaline-right\")) >0 :\n",
    "        for tag in soup.select(\"div.article-metaline-right\"):\n",
    "            tag.extract()\n",
    "            \n",
    "    if len(soup.select(\"span.f2\")) >0 :\n",
    "        for tag in soup.select(\"span.f2\"):\n",
    "            tag.extract()\n",
    "    \n",
    "    return soup \n",
    "\n",
    "# 回應資料\n",
    "def get_resp_data(ele):\n",
    "    span_tags = ele.select(\"span\")\n",
    "    return {\n",
    "        \"tag\"     : span_tags[0].text.strip(),\n",
    "        \"author\"  : span_tags[1].text.strip(),\n",
    "        \"content\" : span_tags[2].text.replace(\": \",\"\").strip(), \n",
    "        \"time\"    : span_tags[3].text.strip()\n",
    "    }\n",
    "\n",
    "\n",
    "def get_data(soup,url):\n",
    "    ### 抓取本文的 作者 , 看板 , 標題 , 時間 \n",
    "    span_tags = soup.select(\"div#main-content span.article-meta-value\")\n",
    "\n",
    "    # 作者\n",
    "    author = span_tags[0].text\n",
    "\n",
    "    # 看板\n",
    "    category = span_tags[1].text\n",
    "\n",
    "    # 標題\n",
    "    title = span_tags[2].text\n",
    "\n",
    "    # 時間\n",
    "    time = span_tags[3].text\n",
    "\n",
    "    ### 抓取本文的 內容 , 回應\n",
    "    push_tags = soup.select(\"div#main-content div.push\")\n",
    "    resp_data = []\n",
    "\n",
    "    if len(push_tags) >0:\n",
    "\n",
    "        for ele in push_tags:\n",
    "            ele.extract()  # 宣告從 div#main-content 中,拔除 div.push 標籤\n",
    "\n",
    "            resp = get_resp_data(ele)\n",
    "\n",
    "            resp_data.append(resp)\n",
    "\n",
    "    ### 內容\n",
    "    soup = remove_dirty_tag(soup)\n",
    "    content = soup.select(\"div#main-content\")[0].text.strip()\n",
    "    \n",
    "    return {\n",
    "        \"author\" : author,\n",
    "        \"category\" : category,\n",
    "        \"title\" : title,\n",
    "        \"time\" : time,\n",
    "        \"resp_data\" : resp_data,\n",
    "        \"content\" : content,\n",
    "        \"url\"     : url   # 新增連結欄位\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "## main 程式\n",
    "\n",
    "## 取得本文 source code\n",
    "url = \"https://www.ptt.cc/bbs/Stock/index.html\"\n",
    "headers = {\n",
    "    \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\"\n",
    "}\n",
    "\n",
    "res = requests.get(url,headers=headers)\n",
    "soup = bs(res.text,\"lxml\")\n",
    "\n",
    "links = []\n",
    "\n",
    "print(\"* 取得本文 source code 完成！\")\n",
    "\n",
    "\n",
    "### 抓取首頁文章連結\n",
    "for a_tag in soup.select(\"div#main-container div.r-ent div.title a\"):\n",
    "    \n",
    "    # 過濾 版規 & 盤後閒聊 / 盤中閒聊\n",
    "    title = a_tag.text\n",
    "    \n",
    "    if \"股票板板規\" in title or \"盤後閒聊\" in title or \"盤中閒聊\" in title :\n",
    "        continue # 跳過此步, 執行下一動迴圈\n",
    "    else:\n",
    "        url = \"https://www.ptt.cc\" + a_tag[\"href\"]\n",
    "        links.append(url)\n",
    "        \n",
    "print(\"* 抓取首頁文章連結 完成！\")\n",
    "\n",
    "        \n",
    "### 抓取 分頁文章 連結\n",
    "for i in range(1,6):\n",
    "    \n",
    "    # 建構 '上頁' 連結\n",
    "    link = soup.select(\"div#action-bar-container div.btn-group-paging a\")[1][\"href\"]\n",
    "    previous_link = \"https://www.ptt.cc\" + link\n",
    "\n",
    "    res = requests.get(previous_link,headers=headers)\n",
    "    soup = bs(res.text,\"lxml\")\n",
    "\n",
    "    for a_tag in soup.select(\"div#main-container div.r-ent div.title a\"):\n",
    "\n",
    "        # 過濾 版規 & 盤後閒聊 / 盤中閒聊\n",
    "        title = a_tag.text\n",
    "\n",
    "        if \"股票板板規\" in title or \"盤後閒聊\" in title or \"盤中閒聊\" in title :\n",
    "            continue # 跳過此步, 執行下一動迴圈\n",
    "        else:\n",
    "            url = \"https://www.ptt.cc\" + a_tag[\"href\"]\n",
    "            links.append(url)\n",
    "            \n",
    "    print(\"{} is ok.\".format(previous_link))\n",
    "\n",
    "print(\"* 抓取分頁文章連結 完成！\")\n",
    "\n",
    "\n",
    "### 抓取文章本文 source code + 清理資料\n",
    "\n",
    "# url = links[11]\n",
    "\n",
    "dataList = []\n",
    "for url in links[:10]:      ### 教學用 , 先限定10筆\n",
    "    res2 = requests.get(url,headers=headers)\n",
    "    soup2 = bs(res2.text,\"lxml\")\n",
    "\n",
    "    # 透過 get_data 從 soup2 解析出 dict 資料\n",
    "    data = get_data(soup2,url)\n",
    "    dataList.append(data)\n",
    "\n",
    "    print(\"{} is ok.\".format(url))\n",
    "    \n",
    "print(\"* 抓取文章資料 完成！\")\n",
    "\n",
    "### 資料落地\n",
    "\n",
    "# 檢查 sample 資料夾是否存在\n",
    "# 不存在 -> 新建一個資料夾\n",
    "# if not os.path.exists(\"sample\"):\n",
    "#     os.mkdir(\"sample\")\n",
    "    \n",
    "# for data in dataList:\n",
    "\n",
    "#     with open(\"sample/{}.txt\".format(data[\"title\"].replace(\"/\",\"_\")),\"w\") as out_file:\n",
    "\n",
    "#         records = \"\"\n",
    "\n",
    "#         for key in data:\n",
    "#             if key == \"resp_data\":\n",
    "#                 continue\n",
    "\n",
    "#             # records 併接\n",
    "#             records += \"{} : {}\\n\".format(key ,data[key])\n",
    "\n",
    "#         records += \"=\"*80\n",
    "#         records += \"\\n\"\n",
    "\n",
    "#         # 回應處理\n",
    "#         resp = \"\"\n",
    "\n",
    "#         for ele in data[\"resp_data\"]:\n",
    "#             resp += \"{},{},{},{}\\n\".format(ele[\"tag\"],ele[\"author\"],ele[\"content\"],ele[\"time\"])\n",
    "\n",
    "#         records += resp\n",
    "\n",
    "#         out_file.write(records)\n",
    "        \n",
    "# print(\"* 資料落地 完成！\")\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08deed45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# 建立 DataFrame\n",
    "df = pd.DataFrame(dataList)\n",
    "# df\n",
    "\n",
    "# 選擇特定欄位\n",
    "# print(df[\"author\"])\n",
    "# print(df[ [\"author\",\"title\",\"url\"] ])\n",
    "# df[ [\"author\",\"title\",\"url\"] ]\n",
    "\n",
    "\n",
    "# 選取 子 DataFrame\n",
    "# df2 = df[ [\"author\",\"title\",\"url\"] ]\n",
    "# df2\n",
    "# df3 = df[ [\"author\" , \"content\",\"time\"] ]\n",
    "# df3\n",
    "\n",
    "# 修改欄位名稱\n",
    "# df3.columns = [\"作者\",\"內容\",\"時間\"]\n",
    "# df3\n",
    "\n",
    "# 造新欄位\n",
    "\n",
    "# df3[\"testQQ\"] = \"ABCD\"\n",
    "df3[\"暱稱\"] = df3[\"作者\"].str.extract(r'.*\\((.*)\\).*')  ## 使用正規表達式 , 比對字串\n",
    "\n",
    "# .  -> 任意字元\n",
    "# *  -> 可不出現 or 出現1次以上\n",
    "# \\( -> 比對中 , 有 「(」符號出現者\n",
    "# () -> 期望抓出的字串\n",
    "\n",
    "## \\((.*)\\)   --> 比對字串中 , 結構要是 (XXXX) 的字 , 並抓出 XXXX\n",
    "\n",
    "## ex: \n",
    "#   (abcdefg) --> 抓到 abcdefg\n",
    "#   abc(d)efg --> 抓到 d\n",
    "#   abc(defg  --> 抓不到\n",
    "#   a(bcd)    --> 抓到 bcd\n",
    "\n",
    "\n",
    "# 過濾資料\n",
    "# df3[ df3[\"內容\"].str.contains(\"ARK\")  ]\n",
    "# df3[ df3[\"暱稱\"] == \"qk123\"] \n",
    "# df\n",
    "\n",
    "\n",
    "# 輸出成 excel 檔\n",
    "# df3.to_excel(\"test-ptt-data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f18bad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### df 輸出成 excel 檔\n",
    "\n",
    "df4 = df[[\"author\",\"category\",\"title\",\"time\",\"content\",\"url\"]]\n",
    "df4.columns = [\"作者\",\"分類\",\"標題\",\"時間\",\"內容\",\"連結\"]\n",
    "\n",
    "# df4\n",
    "\n",
    "# 轉成 excel\n",
    "# df4.to_excel(\"raw-ptt-data.xlsx\")\n",
    "# df4.to_excel(\"raw-ptt-data.xlsx\",index=False,sheet_name=\"文章本文\")\n",
    "\n",
    "# 轉成 csv\n",
    "# df4.to_csv(\"raw-ptt-data.csv\",index=False,encoding=\"utf_8_sig\")\n",
    "\n",
    "# 回文資料,  收到另一個 df 去\n",
    "resp_list = []\n",
    "i=0\n",
    "\n",
    "for ele in dataList:\n",
    "#     print(i , ele[\"resp_data\"])\n",
    "    for resp in ele[\"resp_data\"]:\n",
    "        resp[\"article_no\"] = i\n",
    "        resp_list.append(resp)\n",
    "    \n",
    "#     print(\"-\"*80)\n",
    "    i+=1\n",
    "\n",
    "# print(resp_list)\n",
    "\n",
    "resp_df = pd.DataFrame(resp_list)\n",
    "resp_df.columns = [\"類型\",\"作者\",\"內容\",\"時間\",\"本文編號\"]\n",
    "# resp_df[ (resp_df[\"本文編號\"] == 1) & (resp_df[\"類型\"] == \"推\")]\n",
    "resp_df\n",
    "\n",
    "# 將回應切分成不同 sheet 儲存\n",
    "with pd.ExcelWriter(\"2021-1116-ptt-stock-data.xlsx\") as writer:\n",
    "    df4.to_excel(writer,sheet_name=\"文章本文\")\n",
    "    resp_df.to_excel(writer,sheet_name=\"回應內容\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
