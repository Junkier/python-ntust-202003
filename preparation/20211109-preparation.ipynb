{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed46c65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PTT 股票版 \n",
    "\n",
    "### 取得首頁 source code\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs \n",
    "\n",
    "url = \"https://www.ptt.cc/bbs/Stock/index.html\"\n",
    "headers = {\n",
    "    \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\"\n",
    "}\n",
    "\n",
    "res = requests.get(url,headers=headers)\n",
    "soup = bs(res.text,\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36984ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ptt.cc/bbs/Stock/M.1636425256.A.39B.html [標的] 4961 天鈺 多\n",
      "https://www.ptt.cc/bbs/Stock/M.1636425693.A.235.html [新聞] 投顧：基本面強勁 長榮有望過7月高點223\n",
      "https://www.ptt.cc/bbs/Stock/M.1636425790.A.045.html Re: [請益] 菜雞請問存股族除息怎麼操作?\n"
     ]
    }
   ],
   "source": [
    "### 抓取首頁文章連結\n",
    "links = []\n",
    "for a_tag in soup.select(\"div#main-container div.r-ent div.title a\"):\n",
    "    \n",
    "    # 過濾 版規 & 盤後閒聊 / 盤中閒聊\n",
    "    title = a_tag.text\n",
    "    \n",
    "    if \"股票板板規\" in title or \"盤後閒聊\" in title or \"盤中閒聊\" in title :\n",
    "        continue # 跳過此步, 執行下一動迴圈\n",
    "    else:\n",
    "        url = \"https://www.ptt.cc\" + a_tag[\"href\"]\n",
    "        print(url,title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f58a273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ptt.cc/bbs/Stock/index4999.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/index4998.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/index4997.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/index4996.html is ok.\n",
      "https://www.ptt.cc/bbs/Stock/index4995.html is ok.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "### 抓取 分頁文章 連結\n",
    "\n",
    "headers = {\n",
    "    \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\"\n",
    "}\n",
    "\n",
    "for i in range(1,6):\n",
    "    \n",
    "    # 建構 '上頁' 連結\n",
    "    link = soup.select(\"div#action-bar-container div.btn-group-paging a\")[1][\"href\"]\n",
    "    previous_link = \"https://www.ptt.cc\" + link\n",
    "\n",
    "    res = requests.get(previous_link,headers=headers)\n",
    "    soup = bs(res.text,\"lxml\")\n",
    "\n",
    "    for a_tag in soup.select(\"div#main-container div.r-ent div.title a\"):\n",
    "\n",
    "        # 過濾 版規 & 盤後閒聊 / 盤中閒聊\n",
    "        title = a_tag.text\n",
    "\n",
    "        if \"股票板板規\" in title or \"盤後閒聊\" in title or \"盤中閒聊\" in title :\n",
    "            continue # 跳過此步, 執行下一動迴圈\n",
    "        else:\n",
    "            url = \"https://www.ptt.cc\" + a_tag[\"href\"]\n",
    "            links.append(url)\n",
    "            \n",
    "    print(\"{} is ok.\".format(previous_link))\n",
    "        \n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "189015f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ptt.cc/bbs/Stock/M.1636419064.A.3AD.html\n"
     ]
    }
   ],
   "source": [
    "### 抓取文章本文 source code \n",
    "url = links[11]\n",
    "print(url)\n",
    "\n",
    "headers = {\n",
    "    \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\"\n",
    "}\n",
    "\n",
    "res2 = requests.get(url,headers=headers)\n",
    "soup2 = bs(res2.text,\"lxml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffb627d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author : fgf (今年不太冷)\n",
      "category : Stock\n",
      "title : [請益] 菜雞請問存股族除息怎麼操作?\n",
      "time : Tue Nov  9 08:51:02 2021\n"
     ]
    }
   ],
   "source": [
    "### 抓取本文的 作者 , 看板 , 標題 , 時間 \n",
    "span_tags = soup2.select(\"div#main-content span.article-meta-value\")\n",
    "\n",
    "# 作者\n",
    "author = span_tags[0].text\n",
    "print(\"author :\",author)\n",
    "\n",
    "# 看板\n",
    "category = span_tags[1].text\n",
    "print(\"category :\",category)\n",
    "\n",
    "# 標題\n",
    "title = span_tags[2].text\n",
    "print(\"title :\",title)\n",
    "\n",
    "# 時間\n",
    "time = span_tags[3].text\n",
    "print(\"time :\",time)\n",
    "\n",
    "# span_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f9e636da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### 抓取本文的 回應\n",
    "\n",
    "#############\n",
    "# 為了標籤拔除 , 故先抓取 回應資料\n",
    "# 加入拔除標籤動作\n",
    "def get_resp_data(ele):\n",
    "    span_tags = ele.select(\"span\")\n",
    "    return {\n",
    "        \"tag\"     : span_tags[0].text.strip(),\n",
    "        \"author\"  : span_tags[1].text.strip(),\n",
    "        \"content\" : span_tags[2].text.replace(\": \",\"\").strip(), \n",
    "        \"time\"    : span_tags[3].text.strip()\n",
    "    }\n",
    "\n",
    "\n",
    "push_tags = soup2.select(\"div#main-content div.push\")\n",
    "resp_data = []\n",
    "\n",
    "if len(push_tags) >0:\n",
    "    \n",
    "    for ele in push_tags:\n",
    "        ele.extract()  # 宣告從 div#main-content 中,拔除 div.push 標籤\n",
    "        \n",
    "        resp = get_resp_data(ele)\n",
    "        \n",
    "        resp_data.append(resp)\n",
    "    \n",
    "# print(resp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "94160852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### 內容\n",
    "# print(soup2.select(\"div#main-content\")[0].text)\n",
    "\n",
    "# 1. 移除標籤\n",
    "# - div.article-metaline\n",
    "# - div.article-metaline-right\n",
    "# - span.f2\n",
    "\n",
    "def remove_dirty_tag(soup):\n",
    "    \n",
    "    # 若存在 , 則移除標籤\n",
    "    if len(soup.select(\"div.article-metaline\")) >0 :\n",
    "        \n",
    "        # 標籤可能多項 , 使用 for-loop 移除\n",
    "        for tag in soup.select(\"div.article-metaline\"):\n",
    "            tag.extract()\n",
    "            \n",
    "    if len(soup.select(\"div.article-metaline-right\")) >0 :\n",
    "        for tag in soup.select(\"div.article-metaline-right\"):\n",
    "            tag.extract()\n",
    "            \n",
    "    if len(soup.select(\"span.f2\")) >0 :\n",
    "        for tag in soup.select(\"span.f2\"):\n",
    "            tag.extract()\n",
    "    \n",
    "    return soup \n",
    "\n",
    "\n",
    "\n",
    "soup2 = remove_dirty_tag(soup2)\n",
    "\n",
    "# 2. 抓取文字\n",
    "content = soup2.select(\"div#main-content\")[0].text.strip()\n",
    "# print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6c5f47f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 取得首頁 source code 完成！\n",
      "* 取得首頁文章連結 完成！\n",
      "https://www.ptt.cc/bbs/Gossiping/index39009.html is ok.\n",
      "https://www.ptt.cc/bbs/Gossiping/index39008.html is ok.\n",
      "https://www.ptt.cc/bbs/Gossiping/index39007.html is ok.\n",
      "https://www.ptt.cc/bbs/Gossiping/index39006.html is ok.\n",
      "https://www.ptt.cc/bbs/Gossiping/index39005.html is ok.\n",
      "* 抓取分頁文章連結 完成！\n",
      "https://www.ptt.cc/bbs/Gossiping/M.1636430219.A.177.html is ok.\n",
      "https://www.ptt.cc/bbs/Gossiping/M.1636430265.A.8DA.html is ok.\n",
      "https://www.ptt.cc/bbs/Gossiping/M.1636430270.A.191.html is ok.\n",
      "https://www.ptt.cc/bbs/Gossiping/M.1636430279.A.DB3.html is ok.\n",
      "https://www.ptt.cc/bbs/Gossiping/M.1636430280.A.BFD.html is ok.\n",
      "https://www.ptt.cc/bbs/Gossiping/M.1636430374.A.1F9.html is ok.\n",
      "https://www.ptt.cc/bbs/Gossiping/M.1636430380.A.0BC.html is ok.\n",
      "https://www.ptt.cc/bbs/Gossiping/M.1636430421.A.153.html is ok.\n",
      "https://www.ptt.cc/bbs/Gossiping/M.1636430475.A.58A.html is ok.\n",
      "https://www.ptt.cc/bbs/Gossiping/M.1636430483.A.43A.html is ok.\n",
      "* 抓取本文資料 完成！\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "### 組合程式\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs \n",
    "\n",
    "\n",
    "# 移除標籤\n",
    "# - div.article-metaline\n",
    "# - div.article-metaline-right\n",
    "# - span.f2\n",
    "def remove_dirty_tag(soup):\n",
    "    \n",
    "    # 若存在 , 則移除標籤\n",
    "    if len(soup.select(\"div.article-metaline\")) >0 :\n",
    "        \n",
    "        # 標籤可能多項 , 使用 for-loop 移除\n",
    "        for tag in soup.select(\"div.article-metaline\"):\n",
    "            tag.extract()\n",
    "            \n",
    "    if len(soup.select(\"div.article-metaline-right\")) >0 :\n",
    "        for tag in soup.select(\"div.article-metaline-right\"):\n",
    "            tag.extract()\n",
    "            \n",
    "    if len(soup.select(\"span.f2\")) >0 :\n",
    "        for tag in soup.select(\"span.f2\"):\n",
    "            tag.extract()\n",
    "    \n",
    "    return soup\n",
    "\n",
    "def get_resp_data(ele):\n",
    "    span_tags = ele.select(\"span\")\n",
    "    return {\n",
    "        \"tag\"     : span_tags[0].text.strip(),\n",
    "        \"author\"  : span_tags[1].text.strip(),\n",
    "        \"content\" : span_tags[2].text.replace(\": \",\"\").strip(), \n",
    "        \"time\"    : span_tags[3].text.strip()\n",
    "    }\n",
    "\n",
    "\n",
    "def get_data(soup,url):\n",
    "    ### 抓取本文的 作者 , 看板 , 標題 , 時間 \n",
    "    span_tags = soup.select(\"div#main-content span.article-meta-value\")\n",
    "\n",
    "    # 作者\n",
    "    author = span_tags[0].text\n",
    "\n",
    "    # 看板\n",
    "    category = span_tags[1].text\n",
    "\n",
    "    # 標題\n",
    "    title = span_tags[2].text\n",
    "\n",
    "    # 時間\n",
    "    time = span_tags[3].text\n",
    "\n",
    "    ### 抓取本文的 回應\n",
    "\n",
    "    #############\n",
    "    # 為了標籤拔除 , 故先抓取 回應資料\n",
    "    # 加入拔除標籤動作\n",
    "    push_tags = soup.select(\"div#main-content div.push\")\n",
    "    resp_data = []\n",
    "\n",
    "    if len(push_tags) >0:\n",
    "\n",
    "        for ele in push_tags:\n",
    "            ele.extract()  # 宣告從 div#main-content 中,拔除 div.push 標籤\n",
    "\n",
    "            resp = get_resp_data(ele)\n",
    "\n",
    "            resp_data.append(resp)\n",
    "            \n",
    "    ### 內容\n",
    "    soup = remove_dirty_tag(soup)\n",
    "    content = soup.select(\"div#main-content\")[0].text.strip()\n",
    "    \n",
    "    \n",
    "    ### 包成 dict return 回去\n",
    "    return {\n",
    "        \"author\" : author,\n",
    "        \"category\" : category,\n",
    "        \"title\" : title,\n",
    "        \"time\" : time,\n",
    "        \"resp_data\" : resp_data,\n",
    "        \"content\" : content,\n",
    "        \"url\" : url\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "### main 程式\n",
    "\n",
    "## 取得首頁 source code\n",
    "base_url = \"https://www.ptt.cc/bbs/Stock/index.html\"\n",
    "\n",
    "headers = {\n",
    "    \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# res = sess.get(base_url,headers=headers)    # 後半段\n",
    "res = requests.get(base_url,headers=headers)\n",
    "soup = bs(res.text,\"lxml\")\n",
    "\n",
    "print(\"* 取得首頁 source code 完成！\")\n",
    "\n",
    "\n",
    "## 抓取首頁文章連結\n",
    "links = []\n",
    "\n",
    "for a_tag in soup.select(\"div#main-container div.r-ent div.title a\"):\n",
    "    \n",
    "    # 過濾 版規 & 盤後閒聊 / 盤中閒聊\n",
    "    title = a_tag.text\n",
    "    \n",
    "    if \"股票板板規\" in title or \"盤後閒聊\" in title or \"盤中閒聊\" in title :\n",
    "        continue # 跳過此步, 執行下一動迴圈\n",
    "    else:\n",
    "        url = \"https://www.ptt.cc\" + a_tag[\"href\"]\n",
    "        links.append(url)\n",
    "        \n",
    "print(\"* 取得首頁文章連結 完成！\")\n",
    "\n",
    "\n",
    "        \n",
    "## 抓取 分頁文章 連結\n",
    "for i in range(1,6):\n",
    "    \n",
    "    # 建構 '上頁' 連結\n",
    "    link = soup.select(\"div#action-bar-container div.btn-group-paging a\")[1][\"href\"]\n",
    "    previous_link = \"https://www.ptt.cc\" + link\n",
    "\n",
    "    res = requests.get(previous_link,headers=headers)\n",
    "#     res = sess.get(previous_link,headers=headers)  # 後半段\n",
    "    soup = bs(res.text,\"lxml\")\n",
    "\n",
    "    for a_tag in soup.select(\"div#main-container div.r-ent div.title a\"):\n",
    "\n",
    "        # 過濾 版規 & 盤後閒聊 / 盤中閒聊\n",
    "        title = a_tag.text\n",
    "\n",
    "        if \"股票板板規\" in title or \"盤後閒聊\" in title or \"盤中閒聊\" in title :\n",
    "            continue # 跳過此步, 執行下一動迴圈\n",
    "        else:\n",
    "            url = \"https://www.ptt.cc\" + a_tag[\"href\"]\n",
    "            links.append(url)\n",
    "            \n",
    "    print(\"{} is ok.\".format(previous_link))\n",
    "        \n",
    "print(\"* 抓取分頁文章連結 完成！\")\n",
    "\n",
    "\n",
    "## 抓取文章本文 source code + 資料清洗\n",
    "\n",
    "dataList = []\n",
    "\n",
    "for url in links[:10]:\n",
    "    res2 = requests.get(url,headers=headers)\n",
    "#     res2 = sess.get(url,headers=headers)   # 後半段\n",
    "    soup2 = bs(res2.text,\"lxml\")\n",
    "    data = get_data(soup2,url)\n",
    "    \n",
    "    dataList.append(data)\n",
    "    \n",
    "    print(\"{} is ok.\".format(url))\n",
    "    \n",
    "print(\"* 抓取本文資料 完成！\")\n",
    "\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e180903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ele = dataList[0]\n",
    "for key in ele:\n",
    "    print(key , \":\" , ele[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5d152ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 資料落地\n",
    "import os\n",
    "\n",
    "for data in dataList:\n",
    "\n",
    "    file_name = data[\"title\"]\n",
    "    \n",
    "    # 檢查 sample 資料夾是否存在\n",
    "    # 若不存在 , 則新建立一個\n",
    "    if not os.path.exists(\"sample\"):\n",
    "        os.mkdir(\"sample\")\n",
    "\n",
    "    with open(\"sample/{}.txt\".format(file_name),\"w\") as out_file:\n",
    "\n",
    "        record = \"\"\n",
    "\n",
    "        # 除回應外 , 其餘資料拼接\n",
    "        for key in data:\n",
    "            if key != \"resp_data\": record += \"{}: {}\\n\".format(key,data[key])\n",
    "                \n",
    "        # 回應分隔線\n",
    "        record += (\"=\"*80)\n",
    "        record += \"\\n\"\n",
    "        \n",
    "        # 回應資料\n",
    "        resp = \"\"\n",
    "        for ele in data[\"resp_data\"]:\n",
    "            resp += \"{},{},{},{}\\n\".format(ele[\"tag\"],ele[\"author\"],ele[\"content\"],ele[\"time\"])\n",
    "            \n",
    "        record += resp\n",
    "        out_file.write(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec08a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 程式轉成 .py 檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009658dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9309fd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a3f8fb17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### PTT 八卦板\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs \n",
    "\n",
    "base_url = \"https://www.ptt.cc/bbs/Gossiping/index.html\"\n",
    "\n",
    "headers = {\n",
    "    \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\"\n",
    "}\n",
    "\n",
    "res4 = requests.get(base_url,headers=headers)\n",
    "soup4 = bs(res4.text,\"lxml\")\n",
    "# soup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f308b905",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 同意 18 歲驗證\n",
    "api = \"https://www.ptt.cc/ask/over18\"\n",
    "headers = {\n",
    "    \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"from\": \"/bbs/Gossiping/index.html\",\n",
    "    \"yes\" : \"yes\"\n",
    "}\n",
    "\n",
    "res3 = requests.post(api,headers=headers,data=payload)\n",
    "# print(res3.text)\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4e86c042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### 使用 session 紀錄狀態\n",
    "\n",
    "\n",
    "## 1. 建立 session \n",
    "sess = requests.session()\n",
    " \n",
    "## 2. 同意 18 歲驗證 (如同 會員登入)\n",
    "api = \"https://www.ptt.cc/ask/over18\"\n",
    "headers = {\n",
    "    \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"from\": \"/bbs/Gossiping/index.html\",\n",
    "    \"yes\" : \"yes\"\n",
    "}\n",
    "\n",
    "# 改用 sess 發 requests \n",
    "# res3 = requests.post(api,headers=headers,data=payload)\n",
    "res3 = sess.post(api,headers=headers,data=payload)\n",
    "\n",
    "\n",
    "## 3. 再用 sess 向八卦版爬取文章\n",
    "base_url = \"https://www.ptt.cc/bbs/Gossiping/index.html\"\n",
    "\n",
    "headers = {\n",
    "    \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\"\n",
    "}\n",
    "\n",
    "\n",
    "# stateful session 發 requests (已紀錄 over18)\n",
    "res4 = sess.get(base_url,headers=headers)\n",
    "\n",
    "# stateless 發 requests  (未紀錄 over18)\n",
    "# res4 = requests.get(base_url,headers=headers)\n",
    "\n",
    "\n",
    "soup4 = bs(res4.text,\"lxml\")\n",
    "# soup4\n",
    "\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f08b69b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
